{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# Script to evaluate citation delay\n",
    "# citation_id - patent making a citation \n",
    "# patent_id - patent receiving a citation \n",
    "\n",
    "# Renato Kogeyama\n",
    "\n",
    "\n",
    "# Oct 22, 2020\n",
    "# The original script requires more than 32 GB RAM\n",
    "# Changing from pd to dd (dask dataframe)\n",
    "\n",
    "# Aug 19, 2020\n",
    "# Included gzip\n",
    "# Run with latest database\n",
    "\n",
    "\n",
    "# Feb 07, 2020\n",
    "# The main offensor of performance in this script is the transformation to timedelta\n",
    "# the solution is to change to numpy\n",
    "# https://stackoverflow.com/questions/52274356/conversion-of-a-timedelta-to-int-very-slow-in-python\n",
    "\n",
    "# Jan 17 2020\n",
    "# Join cit_delay with var_builder\n",
    "# The only thing var_builder was doing was including kind and type \n",
    "\n",
    "\n",
    "# Jan 03 2020\n",
    "# Miami\n",
    "# I am using this script to calculate the average delay in citation - to follow Hall et al, 2001\n",
    "# patent.csv has the following columns\n",
    "# id \ttype \tnumber \tcountry \tdate \tabstract \ttitle \tkind \tnum_claims \tfilename\n",
    "# interest on id, type, date, kind, num_claims\n",
    "\n",
    "# I use two sources, uspatentcitation.tsv and patent.csv\n",
    "# The first is a citation-level dataset with information about the citing patent\n",
    "# The second is a patent-level dataset with information about the patent\n",
    "\n",
    "# Cleaning\n",
    "# I tested in other scripts the quality of the patent identifier\n",
    "# It does not require cleaning - only 4 erros from 6 million patents\n",
    "# The cleaning script is there anyway\n",
    "\n",
    "# Merging\n",
    "# I merge on the citation level (df)\n",
    "\n",
    "\n",
    "# --\n",
    "\n",
    "# First U.S. Patent Issued Today in 1790\n",
    "\n",
    "\n",
    "# July 31, 2001\n",
    "# Press Release\n",
    "# #01-33\n",
    "\n",
    "# On July 31, 1790 Samuel Hopkins was issued the first patent for a process \n",
    "# of making potash, an ingredient used in fertilizer. The patent was signed by \n",
    "# President George Washington. Hopkins was born in Vermont, but was living in \n",
    "# Philadelphia, Pa. when the patent was granted.\n",
    "\n",
    "# The first patent, as well as the more than 6 million patents issued since then, \n",
    "# can be seen on the Department of Commerce's United States Patent and Trademark \n",
    "# Office website at www.uspto.gov. The original document is in the collections of \n",
    "# the Chicago Historical Society.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import dask.dataframe as dd\n",
    "from dask.delayed import delayed\n",
    "import datetime\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(n_workers=1, threads_per_worker=4, processes=False)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_subtract_dates(df):\n",
    "    #conversao de string para data\n",
    "    df[\"citation_date\"] = df[\"citation_date\"].astype(int)\n",
    "    df[\"patent_date\"] = df[\"patent_date\"].astype(int)\n",
    "\n",
    "    # delay is the time interval between grant and citation\n",
    "    # following https://stackoverflow.com/questions/55395387/converting-a-dask-column-to-a-date-and-applying-a-lambda-function?rq=1\n",
    "    df=df.assign(cit_delay=df[\"patent_date\"] - df[\"citation_date\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_df = 'data/cleanuspatentcitation.parquet.gz'\n",
    "patent= 'data/cleanpatent.parquet.gz'\n",
    "dst='data/var_builder.parquet.gz'\n",
    "report_dst='var_builder_report.tex'\n",
    "\n",
    "report=[] #file to export report\n",
    "\n",
    "# df = dd.read_parquet(citation_df, chunksize=128*1024*1024)\n",
    "df = dd.read_parquet(citation_df)\n",
    "pt_df = dd.read_parquet(patent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype={'patent_id':object, 'citation_id':object}\n",
    "#ddf=delayed(pd.read_csv)(citation_df, usecols=['patent_id', 'citation_id', 'date'], dtype=dtype, parse_dates=['date'])\n",
    "#pt_ddf = delayed(pd.read_csv)(patent, usecols=['id', 'date'], dtype={'id':object}, parse_dates=['date']).set_index('id')\n",
    "\n",
    "#df = dd.from_delayed(ddf)\n",
    "#pt_df = dd.from_delayed(pt_ddf)\n",
    "\n",
    "report.append(\"file citation head \\n\")\n",
    "report.append(df.head().to_latex())\n",
    "report.append(\"patent file head \\n\")\n",
    "report.append(pt_df.head().to_latex())\n",
    "\n",
    "df=df.rename(columns = {'date':'patent_date'})\n",
    "pt_df=pt_df.rename(columns = {'date':'citation_date'})\n",
    "\n",
    "# merge between patent data and citations on patent_id (citing)\n",
    "# merging on the citation dataset drops patents without citing\n",
    "# later i could standardize to make patent_id index and use join instead of merge\n",
    "# df = df.set_index('patent_id').persist()\n",
    "df=df.merge(pt_df, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# report.append(\"Info after merging\\n\")\n",
    "# report.append(df.info().to_latex())\n",
    "\n",
    "# date format to allow calculations\n",
    "\n",
    "df=delayed(convert_and_subtract_dates)(df)\n",
    "df=df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if I do not drop nans, the script raises an error later when converting day interval into years\n",
    "# I could substitute with average instead of dropping, this way I do not lose the citation info\n",
    "# however, not always it will be possible to average - cases where there is ony one citation, for example\n",
    "# For this reason, at this point, I'll keep the NAN and circumvent the issues as they arise\n",
    "\n",
    "# df=df.dropna()\n",
    "\n",
    "report.append(\"largest citation delays\\n\")\n",
    "report.append(df.nlargest(15, 'cit_delay').to_latex())\n",
    "report.append(\"smallest citation delays \\n\")\n",
    "report.append(df.nsmallest(15, 'cit_delay').to_latex())\n",
    "\n",
    "report.append(\"describe\\n\")\n",
    "report.append(df.describe().to_latex())\n",
    "\n",
    "report.append(\"head\\n\")\n",
    "report.append(df.head().to_latex())\n",
    "\n",
    "#get_ipython().run_cell_magic('time', '', 'df.hist()')\n",
    "\n",
    "#Check outliers\n",
    "#report.append(\"Check cit delay outliers - 0.15 quantile\")\n",
    "#report.append(df[df[\"cit_delay\"]>df[\"cit_delay\"].quantile(0.15)].sort_values(by=['cit_delay'], ascending=True))\n",
    "\n",
    "#report.append(\"Check cit delay outliers -0.85 quantile\")\n",
    "#report.append(df[df[\"cit_delay\"]<df[\"cit_delay\"].quantile(0.85)].sort_values(by=['cit_delay'], ascending=False))\n",
    "#df.to_parquet(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(report_dst, 'a') as f:\n",
    "    f.write(\"VAR BUILDER\\n\"+str(datetime.datetime.now()) + \"\\n\")\n",
    "    f.writelines([str(x) + \"\\n\" for x in report])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
