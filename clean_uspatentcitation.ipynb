{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sao Paulo, October 30th, 2020\n",
    "This script reads parquet uspatentcitation files, drops rows with errors on patent and date fields.\n",
    "This cleaning aims to avoid later processing problems.\n",
    "\n",
    "This script should offer a report on the dropped rows.\n",
    "Alternatively, it could generate a flag indicating rows with errors.\n",
    "\n",
    "# citation_id - patent making a citation \n",
    "# patent_id - patent receiving a citation \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import dask.dataframe as dd\n",
    "from dask.delayed import delayed\n",
    "import glob\n",
    "from fastparquet import ParquetFile\n",
    "\n",
    "# from dask.distributed import Client\n",
    "# client = Client(n_workers=1, threads_per_worker=4, processes=False)\n",
    "# client\n",
    "\n",
    "def clean_field(df):\n",
    "    cleaning_patent=lambda x:re.sub('([^a-zA-Z0-9]+)', \"\", x)\n",
    "    df.dropna(inplace=True)\n",
    "    df['patent_id']=df['patent_id'].apply(cleaning_patent)\n",
    "    df['citation_id']=df['citation_id'].apply(cleaning_patent)\n",
    "    return df\n",
    "\n",
    "def date_within_boundaries(df):\n",
    "    # Avoid TimeStamp limitations:\n",
    "    # https://stackoverflow.com/questions/50265288/how-to-work-around-python-pandas-dataframes-out-of-bounds-nanosecond-timestamp\n",
    "    df['date']=df['date'].str[:4].astype(int)\n",
    "    #pd.Timestamp.min: Timestamp('1677-09-21 00:12:43.145225')\n",
    "    df['date']=df['date'].apply(lambda x: x if x > 1677 else np.nan)\n",
    "    df=df[df['date'] > 1790] #grant date of the first patent ever issued\n",
    "    #pd.Timestamp.max: Timestamp('2262-04-11 23:47:16.854775807')\n",
    "    df=df[df['date']<2021]\n",
    "    df['date']=df['date'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list=glob.glob(\"parquet/uspatentcitation*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the date of the first patent ever granted, so patents with grant dates previous to these should be wrong\n",
    "# first_patent = datetime.date(1790, 7, 31)\n",
    "# small change from the actual first patent's grant date because one of the citations for n1 seems to be right\n",
    "# first_patent = pd.to_datetime('1790-06-30', format=\"%Y-%m-%d\") \n",
    "\n",
    "dfs = [delayed(pd.read_parquet)(f) for f in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.dask.org/en/latest/delayed-best-practices.html\n",
    "#Every dask.delayed function call is a single operation from Daskâ€™s perspective. \n",
    "#You achieve parallelism by having many delayed calls, not by using only a single one: \n",
    "#Dask will not look inside a function decorated with @dask.delayed and parallelize that code internally. \n",
    "#To accomplish that, it needs your help to find good places to break up a computation.\n",
    "\n",
    "def run_processes(dfs):\n",
    "    myTypes={'patent_id':str, 'citation_id':str, 'date':str}\n",
    "    for i, df in enumerate(dfs):\n",
    "        df=dd.from_delayed(df, meta=myTypes)\n",
    "        df=delayed(clean_field)(df)\n",
    "        df=delayed(date_within_boundaries)(df)\n",
    "        dst='data/citation/clean_'+str(i)+'.parquet.gz'       \n",
    "        df.set_index('citation_id').compute().to_parquet(dst, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.compute(run_processes(dfs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
