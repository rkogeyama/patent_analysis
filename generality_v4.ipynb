{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Script to calculate generality and  application data\n",
    "# Generality: how diverse is the impact of a patent\n",
    "# This is done by calculating the herfindal index of citing patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feb 9th, 2020\n",
    "# It's working and I'm keeping as v3\n",
    "# Now I begin in v4 \n",
    "# This can be used both for generality and originality\n",
    "# also, I can use for multiple classes\n",
    "\n",
    "# Feb 7th, 2020\n",
    "# transforming this in a function\n",
    "\n",
    "# Feb 7th, 2020\n",
    "# While the previous version is already up, I want to improve the script\n",
    "# I want to make calculations with only one script\n",
    "# Also, I want to compare different class systems\n",
    "# this version took 10 minutes - i am moving the old version away\n",
    "\n",
    "# Jan 16th, 2020\n",
    "# Due to performance problems in the HPC, this script was divided in two, the script following this is generality_2\n",
    "# generality > 1 is not an error, but a consequence of adopting WIPO\n",
    "# it seems that the original calculation had only one class per patent\n",
    "# WIPO provides multiple classes - so when you divide by the total number of citations, \n",
    "#  you do not have the proportion of classes cited anymore\n",
    "# to correct this issue, I can calculate Generality and Originality based only on the first WIPO class\n",
    "\n",
    "# Jan 13th, 2020\n",
    "# Script is running but there are two major issues\n",
    "# - there should not exist generality > 1 , so there is an error in calculation\n",
    "# - too many NANs (about 400k), but I will tackle this issue in 'too_many_nans.ipynb'\n",
    "\n",
    "# to tackle the first problem, I'll begin by creating a subset of the database\n",
    "# to do that, I'll use USPTO classification system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trying to save memory is leading to a small nightmare \n",
    "# I am postponing the use of dask modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(class_df, citation_df, generality=True):\n",
    "    #there is a bug in pandas.read_csv\n",
    "    #it fails to classify as object when told so in the options\n",
    "    #so in this script, I guarantee the indexes are objects\n",
    "    #then I match class to citation\n",
    "    #inner matching in a citation-level returns citation level\n",
    "    #i haven't tested but it could also be used to match class to patent\n",
    "\n",
    "    #to guarantee same format for the merge\n",
    "    class_df['id']=class_df['id'].astype(str)\n",
    "    citation_df=citation_df.astype(str)\n",
    "\n",
    "    #join on index is faster\n",
    "    class_df.set_index('id', inplace=True)\n",
    "    if generality:\n",
    "        citation_df.set_index('patent_id', inplace=True)\n",
    "    else:\n",
    "        citation_df.set_index('citation_id', inplace=True)\n",
    "    \n",
    "    #citation level dataset\n",
    "    #join is faster than merge\n",
    "    df=citation_df.join(class_df, how='inner')  \n",
    "\n",
    "    return df #citations with classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_processing(df, generality=True):\n",
    "    #the left dataframe is citation df, which is indexed by patent_id\n",
    "    #when later on I group by citation_id is very possible that NaNs appear\n",
    "    \n",
    "    #considering the second level of class systems\n",
    "    subclass=df.columns[2] #checar\n",
    "#     print(subclass)\n",
    "    #total citation\n",
    "    if generality:\n",
    "        col_name='generality'\n",
    "        total_citation=df.groupby('citation_id').count().iloc[:,0]\n",
    "    else:\n",
    "        col_name='originality'\n",
    "        total_citation=df.groupby('patent_id').count().iloc[:,0]\n",
    "\n",
    "    total_citation=np.square(total_citation)\n",
    "#     print(total_citation.head())\n",
    "    #df square: count citations, square them, and sum\n",
    "    #citation-subclassclass level of observation\n",
    "    if generality:\n",
    "        df=df.groupby(['citation_id', subclass]).count()\n",
    "    else:\n",
    "        df=df.groupby(['patent_id', subclass]).count()\n",
    "\n",
    "    df_squared=np.square(df)\n",
    "\n",
    "    if generality:\n",
    "        df_squared=df_squared.reset_index().groupby('citation_id').sum()\n",
    "    else:\n",
    "        df_squared=df_squared.reset_index().groupby('patent_id').sum()\n",
    "\n",
    "    df=pd.concat([total_citation, df_squared], axis=1) #testado ate aqui, ok\n",
    "    df=df.iloc[:,0:2]\n",
    "#     df=df.rename({1: 'df_squared', 2: 'total_citation'}, axis='columns')\n",
    "    df.columns=['total_citation','df_squared']\n",
    "\n",
    "    df['herfindal']=df['df_squared']/df['total_citation'] #its a measure of concentration\n",
    "\n",
    "    df[col_name]=1-df['herfindal'] # as defined in Hall et al, 2001\n",
    "#     print(df.head())\n",
    "#     print(df2.head())\n",
    "    return df[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citation= 'data/cleanuspatentcitation.csv'\n",
    "citation_df=pd.read_csv(citation, sep=',', usecols=['patent_id', 'citation_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_systems=['wipo', 'ipcr', 'cpc', 'nber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_hist(df, class_system, generality=True):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    if generality:\n",
    "        ax = df['generality'].hist()\n",
    "        ax.set_title('Generality Distribution\\n'+class_system.upper()+'\\n')\n",
    "        filename='./img/gen_histogram_'+class_system.upper()+'.png'  \n",
    "    else:\n",
    "        ax = df['originality'].hist()\n",
    "        ax.set_title('Originality Distribution\\n'+class_system.upper()+'\\n')\n",
    "        filename='./img/orig_histogram_'+class_system.upper()+'.png'  \n",
    "\n",
    "    plt.savefig(filename)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gener_df=citation_df.set_index('citation_id')\n",
    "orig_df=citation_df.set_index('patent_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #generality\n",
    "\n",
    "# for class_system in class_systems:\n",
    "#     classification = 'data/'+class_system+'.csv'\n",
    "# #     class_df=pd.read_csv(classification, dtype=object, usecols=[0,2])\n",
    "#     class_df=pd.read_csv(classification, dtype=object)\n",
    "#     df=preprocessing(class_df, citation_df)\n",
    "#     df=index_processing(df)\n",
    "# #     print(df.to_frame().head())\n",
    "#     gener_df=gener_df.merge(df.to_frame(), how='outer', left_index=True, right_index=True)\n",
    "# #     dst= 'data/'+class_system+'_generality_v4.csv'\n",
    "# #     df.to_csv(dst)\n",
    "# #     plot_hist(df, class_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gener_df=gener_df.iloc[:,1:]\n",
    "# gener_df.columns = class_systems\n",
    "# gener_df.to_csv('data/generality_classes.csv')\n",
    "# gener_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           originality\n",
      "patent_id             \n",
      "3931349            0.0\n",
      "3935991            0.0\n",
      "3943789            0.0\n",
      "3944004            0.0\n",
      "3945191            0.0\n",
      "           originality\n",
      "patent_id             \n",
      "3931349            0.0\n",
      "3935991            0.0\n",
      "3943789            0.0\n",
      "3944004            0.0\n",
      "3945191            0.0\n",
      "           originality\n",
      "patent_id             \n",
      "3931349            0.0\n",
      "3935991            0.0\n",
      "3943789            0.0\n",
      "3944004            0.0\n",
      "3945191            0.0\n",
      "           originality\n",
      "patent_id             \n",
      "3931349            0.0\n",
      "3935991            0.0\n",
      "3943789            0.0\n",
      "3944004            0.0\n",
      "3945191            0.0\n"
     ]
    }
   ],
   "source": [
    "#originality\n",
    "\n",
    "for class_system in class_systems:\n",
    "    classification = 'data/'+class_system+'.csv'\n",
    "#     class_df=pd.read_csv(classification, dtype=object, usecols=[0,2])\n",
    "    class_df=pd.read_csv(classification, dtype=object)\n",
    "    df=preprocessing(class_df, citation_df, generality=False)\n",
    "    df=index_processing(df, generality=False)\n",
    "#     print(df.to_frame().head())\n",
    "    orig_df=orig_df.merge(df.to_frame(), how='outer', left_index=True, right_index=True)\n",
    "\n",
    "#     orig_df=orig_df.merge(df.to_frame(), how='outer', left_index=True, right_index=True)\n",
    "#     dst= 'data/'+class_system+'_originality_v4.csv'\n",
    "#     df.to_csv(dst)\n",
    "#     plot_hist(df, class_system, generality=False)\n",
    "\n",
    "# orig_df=orig_df.iloc[:,1:]\n",
    "# orig_df.columns = class_systems\n",
    "# orig_df.to_csv('data/originality_classes.csv')\n",
    "# orig_df.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
