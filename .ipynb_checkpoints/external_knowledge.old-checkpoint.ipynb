{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jun 8, 2020\n",
    "\n",
    "So far, I collected and calculated variables on citation- and patent-levels. The first contribution is to use centrality measures such as pagerank, katz and eigen, as proxies to relevance, impact and influence. Also, I test various effects including the relevance of industries. So far, to the best of our knowledge, scholarly production  focused on studies of innovation in specific industries. Our approach allows us to understand broader patterns of innovation.\n",
    "\n",
    "Here, I am testing the hypothesis of the relationship between originality and impact, following 2012 Nemet and Johnson.\n",
    "\n",
    "Originality is measured as the number (or proportion) of citation from patents outside their own domain of knowledge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rkogeyam/scripts/')\n",
    "sys.path.append('scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #load citation\n",
    "# usecols=['uuid', 'patent_id', 'citation_id']\n",
    "# file='data/cleanuspatentcitation.csv.gz'\n",
    "# unzipped=gzip.open(file, 'r')\n",
    "# df=pd.read_csv(unzipped, usecols=usecols, dtype=object)\n",
    "# df.set_index('uuid', inplace=True)\n",
    "\n",
    "# #load iv - 1 when different classification, 0 when same\n",
    "# #test done for many class systems - we can begin with one before running all of them\n",
    "# #usecols=['uuid', 'wipo_sector_ext', 'wipo_field_ext', 'ipcr_section_ext', 'ipcr_ipc_class_ext', 'cpc_section_ext', 'cpc_subsection_ext', 'nber_category_ext', 'nber_subcategory_ext']\n",
    "# usecols=['uuid', 'wipo_sector_ext', 'wipo_field_ext'] #choice for wipo is arbitrary\n",
    "# file='data/int_ext_cit_v2.csv.gz'\n",
    "# unzipped=gzip.open(file, 'r')\n",
    "# df2=pd.read_csv(unzipped, usecols=usecols, dtype=object)\n",
    "# df2.set_index('uuid', inplace=True, dtype=object)\n",
    "\n",
    "# #an outer join would lead to the same result as a left\n",
    "# #since there should not have a classification without a citation\n",
    "# df=df.join(df2, how='outer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#pseudo code\n",
    "join citations and classes and put in memory (so each patent does not have to search through 91 million citations)\n",
    "join patents\n",
    "compare citation classes with patent classes:\n",
    "    0 if same class, 1 if different class\n",
    "    count total of citations from different classes and total citation for each patent \n",
    "    desired variable - proportion of citations from different classes  \n",
    "\n",
    "(i do not need to carry everything in the memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #if i do this, i'll achieve exactly what i did back when calculating originality\n",
    "# #i'm better off using that result instead\n",
    "# src='data/originality_classes.csv.gz'\n",
    "# unzipped=gzip.open(src, 'r')\n",
    "# df=pd.read_csv(unzipped, usecols=usecols, dtype=object)\n",
    "# df.set_index('patent_id', inplace=True)\n",
    "\n",
    "# src='data/eigen.csv.gz'\n",
    "# unzipped=gzip.open(src, 'r')\n",
    "# df=pd.read_csv(unzipped, usecols=usecols, dtype=object)\n",
    "# df.set_index('id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols=['id', 'date', 'eigen','cit_received','cit_received_delay','parent_citation', 'pagerank', 'katz']\n",
    "dtypes={'id':object,'date':object, 'cit_received':float, 'cit_received_delay':float, 'parent_citation':float,\n",
    "        'eigen':float, 'pagerank':float, 'katz':float}\n",
    "src='data/dataset.csv.gz'\n",
    "unzipped=gzip.open(src, 'r')\n",
    "df=pd.read_csv(unzipped, usecols=usecols, dtype=object)\n",
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive=df.describe(include=[np.number]).loc[['count','mean','std','min','max']].append(df[num_cols].isnull().sum().rename('isnull'))\n",
    "descriptive.apply(lambda x: x.apply('{:,.2f}'.format)).transpose()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "m-env",
   "language": "python",
   "name": "m-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
